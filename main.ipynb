{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe41ff91",
   "metadata": {},
   "source": [
    "### Importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "545bf9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from alpha_vantage.foreignexchange import ForeignExchange\n",
    "from alpha_vantage.commodities import Commodities\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from xgboost import XGBRegressor\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6427ad95",
   "metadata": {},
   "source": [
    "### Alpha Vantage Setup (Trading API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9305c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api_key = 'GLVZ9GJN4IW7GRUB'\n",
    "api_key = 'K757OWEW19L34ML9'\n",
    "# symbols = ['AAPL', 'MSFT', 'GOOGL', 'TSLA', 'AMZN']  # Multiple stocks for analysis\n",
    "ts = TimeSeries(key=api_key, output_format='pandas')\n",
    "fx = ForeignExchange(key=api_key, output_format='pandas')\n",
    "\n",
    "assets = [\n",
    "    {'symbol': 'AAPL', 'type': 'stock'},\n",
    "    {'symbol': 'MSFT', 'type': 'stock'},\n",
    "    {'symbol': 'TSLA', 'type': 'stock'},\n",
    "    {'symbol': 'AMZN', 'type': 'stock'},\n",
    "    {'symbol': 'EURUSD', 'type': 'forex', 'from_symbol': 'EUR', 'to_symbol': 'USD'},\n",
    "    {'symbol': 'USDJPY', 'type': 'forex', 'from_symbol': 'USD', 'to_symbol': 'JPY'},\n",
    "    # {'symbol': 'XAUUSD', 'type': 'commodity'},  # Gold\n",
    "    # {'symbol': 'XAGUSD', 'type': 'commodity'},  # Silver\n",
    "    {'symbol': 'COPPER', 'type': 'commodity', 'api_method': 'get_copper'},\n",
    "    {'symbol': 'NATURAL_GAS', 'type': 'commodity', 'api_method': 'get_natural_gas'}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a59d6f8",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2366f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "stock_stats = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b097498a",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a60e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    columns = data.columns\n",
    "\n",
    "    # Case 1: Stock or forex style\n",
    "    if '1. open' in columns:\n",
    "        data = data.rename(columns={\n",
    "            '1. open': 'open',\n",
    "            '2. high': 'high',\n",
    "            '3. low': 'low',\n",
    "            '4. close': 'close',\n",
    "            '5. volume': 'volume'\n",
    "        })[['open', 'high', 'low', 'close', 'volume']]\n",
    "\n",
    "    # Case 2: Commodity style (likely just a 'value' column)\n",
    "    elif 'value' in columns:\n",
    "        data = data.rename(columns={'value': 'close'})\n",
    "        data['open'] = data['close']\n",
    "        data['high'] = data['close']\n",
    "        data['low'] = data['close']\n",
    "        data['volume'] = 0\n",
    "        data = data[['open', 'high', 'low', 'close', 'volume']]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown data format: cannot parse columns:\", list(columns))\n",
    "\n",
    "    return data[::-1].reset_index(drop=True)  # sort oldest to newest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48bbeda",
   "metadata": {},
   "source": [
    "### Load the locally stored data or Fetch the data using the API\n",
    "Better to load the data as the API has a limit on the number of requests per day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9072f99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_fetch_data(asset, api_key, directory=\"asset_data\"):\n",
    "    import os\n",
    "    from alpha_vantage.timeseries import TimeSeries\n",
    "    from alpha_vantage.foreignexchange import ForeignExchange\n",
    "    from alpha_vantage.commodities import Commodities\n",
    "\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    symbol = asset['symbol']\n",
    "    filepath = os.path.join(directory, f\"{symbol}.csv\")\n",
    "\n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"Loading cached data for {symbol}\")\n",
    "        df = pd.read_csv(filepath)\n",
    "        df = prepare_data(df)\n",
    "    else:\n",
    "        print(f\"Fetching data for {symbol} from Alpha Vantage...\")\n",
    "\n",
    "        if asset['type'] == 'stock':\n",
    "            ts = TimeSeries(key=api_key, output_format='pandas')\n",
    "            df, _ = ts.get_daily(symbol=symbol, outputsize='full')\n",
    "\n",
    "        elif asset['type'] == 'forex':\n",
    "            fx = ForeignExchange(key=api_key, output_format='pandas')\n",
    "            df, _ = fx.get_currency_exchange_daily(\n",
    "                from_symbol=asset['from_symbol'],\n",
    "                to_symbol=asset['to_symbol'],\n",
    "                outputsize='full'\n",
    "            )\n",
    "            df['5. volume'] = 0\n",
    "\n",
    "        elif asset['type'] == 'commodity':\n",
    "            cm = Commodities(key=api_key, output_format='pandas')\n",
    "            # Dynamically call the correct commodity method\n",
    "            method_name = asset['api_method']  # e.g., 'get_copper', 'get_gold'\n",
    "            if hasattr(cm, method_name):\n",
    "                func = getattr(cm, method_name)\n",
    "                df, _ = func(interval='monthly')\n",
    "                df['5. volume'] = 0\n",
    "            else:\n",
    "                raise ValueError(f\"Commodities API has no method: {method_name}\")\n",
    "\n",
    "        df.to_csv(filepath)\n",
    "        print(f\"Saved {symbol} data to {filepath}\")\n",
    "        df = prepare_data(df)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcfb1d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached data for AAPL\n",
      "Loading cached data for MSFT\n",
      "Loading cached data for TSLA\n",
      "Loading cached data for AMZN\n",
      "Loading cached data for EURUSD\n",
      "Loading cached data for USDJPY\n",
      "Loading cached data for COPPER\n",
      "Loading cached data for NATURAL_GAS\n",
      "                 open              high               low             close  \\\n",
      "0                   .                 .                 .                 .   \n",
      "1                   .                 .                 .                 .   \n",
      "2                   .                 .                 .                 .   \n",
      "3                   .                 .                 .                 .   \n",
      "4                   .                 .                 .                 .   \n",
      "..                ...               ...               ...               ...   \n",
      "541          9330.975          9330.975          9330.975          9330.975   \n",
      "542  9735.82333333334  9735.82333333334  9735.82333333334  9735.82333333334   \n",
      "543  9172.69590909091  9172.69590909091  9172.69590909091  9172.69590909091   \n",
      "544  9531.20090909091  9531.20090909091  9531.20090909091  9531.20090909091   \n",
      "545   9835.0680952381   9835.0680952381   9835.0680952381   9835.0680952381   \n",
      "\n",
      "     volume  \n",
      "0         0  \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "..      ...  \n",
      "541       0  \n",
      "542       0  \n",
      "543       0  \n",
      "544       0  \n",
      "545       0  \n",
      "\n",
      "[546 rows x 5 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.45</td>\n",
       "      <td>3.45</td>\n",
       "      <td>3.45</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.15</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.89</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.03</td>\n",
       "      <td>2.03</td>\n",
       "      <td>2.03</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   open  high   low  close  volume\n",
       "0  3.45  3.45  3.45   3.45       0\n",
       "1  2.15  2.15  2.15   2.15       0\n",
       "2  1.89  1.89  1.89   1.89       0\n",
       "3  2.03  2.03  2.03   2.03       0\n",
       "4  2.25  2.25  2.25   2.25       0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = load_or_fetch_data(symbols[4], api_key)\n",
    "data_dict = {}\n",
    "for asset in assets:\n",
    "    df = load_or_fetch_data(asset, api_key)\n",
    "    data_dict[asset['symbol']] = df\n",
    "\n",
    "\n",
    "print(data_dict[assets[6]['symbol']])\n",
    "df.head()  # Display the first few rows of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f1a799",
   "metadata": {},
   "source": [
    "### Technical indicators for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "415de423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_technical_indicators(df):\n",
    "    df['MA5'] = df['close'].rolling(window=5).mean()\n",
    "    df['MA10'] = df['close'].rolling(window=10).mean()\n",
    "    df['MA20'] = df['close'].rolling(window=20).mean()\n",
    "    df['Return_5'] = df['close'].pct_change(periods=5)\n",
    "    df['Volatility_20'] = df['close'].rolling(window=20).std()\n",
    "    df['RSI'] = compute_rsi(df['close'], 14)\n",
    "    df['MACD'] = compute_macd(df['close'])\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "def compute_rsi(series, period=14):\n",
    "    delta = series.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def compute_macd(series, slow=26, fast=12):\n",
    "    ema_fast = series.ewm(span=fast, adjust=False).mean()\n",
    "    ema_slow = series.ewm(span=slow, adjust=False).mean()\n",
    "    return ema_fast - ema_slow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4d7477",
   "metadata": {},
   "source": [
    "### Visualize which features were selected and how important they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c134041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_xgboost_feature_importance(model, feature_names, symbol):\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(range(len(feature_names)), importances[indices], align='center')\n",
    "    plt.xticks(range(len(feature_names)), [feature_names[i] for i in indices], rotation=45)\n",
    "    plt.title(f\"{symbol} - XGBoost Feature Importances\")\n",
    "    plt.xlabel(\"Features\")\n",
    "    plt.ylabel(\"Importance Score\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b2b2b5",
   "metadata": {},
   "source": [
    "### XGBoost for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87ea33e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(df, target_col='close', symbol=\"\"):\n",
    "    df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "    # target: future return (use percent change)\n",
    "    y = df[target_col].pct_change().shift(-1).dropna()\n",
    "    df = df.iloc[:-1].reset_index(drop=True)  # Align features to y\n",
    "\n",
    "    X = df.drop(columns=[target_col])\n",
    "    model = XGBRegressor()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    plot_xgboost_feature_importance(model, X.columns, symbol)\n",
    "\n",
    "    importances = model.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': importances\n",
    "    }).sort_values(by='Feature').reset_index(drop=True)\n",
    "\n",
    "    print(\"\\nFull Feature Importance Ranking:\")\n",
    "    print(feature_importance_df)\n",
    "\n",
    "    top_features = X.columns[np.argsort(model.feature_importances_)][-5:]\n",
    "    X_selected = X[top_features].copy().reset_index(drop=True)\n",
    "    y_target = df[target_col].iloc[1:].reset_index(drop=True)  # align with prediction target\n",
    "\n",
    "    y_target.name = target_col  # âœ… set the name to 'Close' (important for merging)\n",
    "\n",
    "    return X_selected, y_target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a9109d",
   "metadata": {},
   "source": [
    "### LSTM Forecasting (for multivariate time series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "950f905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_forecast_multivariate(data, target='close'):\n",
    "    assert isinstance(target, str), \"Target must be a string\"\n",
    "    assert target in data.columns, \"Target column not found in input data\"\n",
    "\n",
    "    # Separate features and target\n",
    "    feature_cols = [col for col in data.columns if col != target]\n",
    "    full_data = data[feature_cols + [target]]  # Ensures correct column order\n",
    "\n",
    "    # Scale data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = scaler.fit_transform(full_data)\n",
    "    target_index = full_data.columns.get_loc(target)\n",
    "\n",
    "    # Create LSTM input windows\n",
    "    X_all, y_all = [], []\n",
    "    for i in range(60, len(scaled)):\n",
    "        X_all.append(scaled[i-60:i, :-1])  # input: all features except target\n",
    "        y_all.append(scaled[i, target_index])  # output: target\n",
    "\n",
    "    X_all, y_all = np.array(X_all), np.array(y_all)\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # LSTM model\n",
    "    model = Sequential([\n",
    "        LSTM(64, return_sequences=True, input_shape=(X_all.shape[1], X_all.shape[2])),\n",
    "        LSTM(32),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "    # Predict\n",
    "    pred_scaled = model.predict(X_test)\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "    # Only reverse scale the target column\n",
    "    pred_full = np.zeros((len(pred_scaled), full_data.shape[1]))\n",
    "    actual_full = np.zeros_like(pred_full)\n",
    "    pred_full[:, target_index] = pred_scaled[:, 0]\n",
    "    actual_full[:, target_index] = y_test[:, 0]\n",
    "\n",
    "    pred = scaler.inverse_transform(pred_full)[:, target_index]\n",
    "    actual = scaler.inverse_transform(actual_full)[:, target_index]\n",
    "\n",
    "    return actual, pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524dee28",
   "metadata": {},
   "source": [
    "### Single Symbol Processing - Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "097d5ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing: COPPER ===\n",
      "  open high low close  volume\n",
      "0    .    .   .     .       0\n",
      "1    .    .   .     .       0\n",
      "2    .    .   .     .       0\n",
      "3    .    .   .     .       0\n",
      "4    .    .   .     .       0\n",
      "  open high low close  volume\n",
      "0    .    .   .     .       0\n",
      "1    .    .   .     .       0\n",
      "2    .    .   .     .       0\n",
      "3    .    .   .     .       0\n",
      "4    .    .   .     .       0\n"
     ]
    },
    {
     "ename": "DataError",
     "evalue": "No numeric types to aggregate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mr:\\OMOTEC\\Stock_price_optimization\\env\\lib\\site-packages\\pandas\\core\\window\\rolling.py:371\u001b[0m, in \u001b[0;36mBaseWindow._prep_values\u001b[1;34m(self, values)\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 371\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mensure_float64\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mpandas/_libs/algos_common_helper.pxi:42\u001b[0m, in \u001b[0;36mpandas._libs.algos.ensure_float64\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '.'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mr:\\OMOTEC\\Stock_price_optimization\\env\\lib\\site-packages\\pandas\\core\\window\\rolling.py:452\u001b[0m, in \u001b[0;36mBaseWindow._apply_series\u001b[1;34m(self, homogeneous_func, name)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 452\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prep_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mr:\\OMOTEC\\Stock_price_optimization\\env\\lib\\site-packages\\pandas\\core\\window\\rolling.py:373\u001b[0m, in \u001b[0;36mBaseWindow._prep_values\u001b[1;34m(self, values)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 373\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot handle this type -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;66;03m# Convert inf to nan for C funcs\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot handle this type -> object",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDataError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m---> 18\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43madd_technical_indicators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m X_selected, y_target \u001b[38;5;241m=\u001b[39m select_features(data)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_selected\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,X_selected)\n",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m, in \u001b[0;36madd_technical_indicators\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21madd_technical_indicators\u001b[39m(df):\n\u001b[1;32m----> 2\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMA5\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrolling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMA10\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mrolling(window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m      4\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMA20\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mrolling(window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32mr:\\OMOTEC\\Stock_price_optimization\\env\\lib\\site-packages\\pandas\\core\\window\\rolling.py:2259\u001b[0m, in \u001b[0;36mRolling.mean\u001b[1;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   2216\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m   2217\u001b[0m     template_header,\n\u001b[0;32m   2218\u001b[0m     create_section_header(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2257\u001b[0m     engine_kwargs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2258\u001b[0m ):\n\u001b[1;32m-> 2259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2263\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mr:\\OMOTEC\\Stock_price_optimization\\env\\lib\\site-packages\\pandas\\core\\window\\rolling.py:1625\u001b[0m, in \u001b[0;36mRollingAndExpandingMixin.mean\u001b[1;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   1623\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_apply(sliding_mean, engine_kwargs)\n\u001b[0;32m   1624\u001b[0m window_func \u001b[38;5;241m=\u001b[39m window_aggregations\u001b[38;5;241m.\u001b[39mroll_mean\n\u001b[1;32m-> 1625\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mr:\\OMOTEC\\Stock_price_optimization\\env\\lib\\site-packages\\pandas\\core\\window\\rolling.py:619\u001b[0m, in \u001b[0;36mBaseWindow._apply\u001b[1;34m(self, func, name, numeric_only, numba_args, **kwargs)\u001b[0m\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_columnwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhomogeneous_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_tablewise(homogeneous_func, name, numeric_only)\n",
      "File \u001b[1;32mr:\\OMOTEC\\Stock_price_optimization\\env\\lib\\site-packages\\pandas\\core\\window\\rolling.py:472\u001b[0m, in \u001b[0;36mBaseWindow._apply_columnwise\u001b[1;34m(self, homogeneous_func, name, numeric_only)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_numeric_only(name, numeric_only)\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 472\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhomogeneous_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj, numeric_only)\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;66;03m# GH 12541: Special case for count where we support date-like types\u001b[39;00m\n",
      "File \u001b[1;32mr:\\OMOTEC\\Stock_price_optimization\\env\\lib\\site-packages\\pandas\\core\\window\\rolling.py:454\u001b[0m, in \u001b[0;36mBaseWindow._apply_series\u001b[1;34m(self, homogeneous_func, name)\u001b[0m\n\u001b[0;32m    452\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prep_values(obj\u001b[38;5;241m.\u001b[39m_values)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DataError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo numeric types to aggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    456\u001b[0m result \u001b[38;5;241m=\u001b[39m homogeneous_func(values)\n\u001b[0;32m    457\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_axis_for_step(obj\u001b[38;5;241m.\u001b[39mindex, result)\n",
      "\u001b[1;31mDataError\u001b[0m: No numeric types to aggregate"
     ]
    }
   ],
   "source": [
    "# symbol = symbols[4]  # Use the first symbol for initial processing\n",
    "# print(f\"\\n=== Processing: {symbol} ===\")\n",
    "# # data, _ = ts.get_daily(symbol=symbol, outputsize='full')\n",
    "# # data = prepare_data(data)\n",
    "# data = load_or_fetch_data(symbol, api_key)\n",
    "\n",
    "\n",
    "# Choose asset by symbol or index\n",
    "symbol = assets[6]['symbol']  # Pick from structured list\n",
    "print(f\"\\n=== Processing: {symbol} ===\")\n",
    "\n",
    "# Get preloaded data from dictionary (not calling API again)\n",
    "data = data_dict[symbol]\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "print(data.head())\n",
    "data = add_technical_indicators(data)\n",
    "X_selected, y_target = select_features(data)\n",
    "\n",
    "\n",
    "print(\"X_selected\\n\",X_selected)\n",
    "print(\"y_target\\n\",y_target)\n",
    "\n",
    "merged_data = pd.concat([X_selected, y_target], axis=1).dropna().reset_index(drop=True)\n",
    "\n",
    "actual, pred = lstm_forecast_multivariate(merged_data, target='close')\n",
    "\n",
    "print(\"actual\\n\", actual)\n",
    "print(\"pred\\n\", pred)\n",
    "\n",
    "print(\"NaN count per column in merged_data:\")\n",
    "print(merged_data.isna().sum())\n",
    "\n",
    "# Storing the volatility and cumulative return\n",
    "initial_price = actual[0]\n",
    "final_price = actual[-1]\n",
    "cumulative_return = (final_price - initial_price) / initial_price\n",
    "volatility = np.std(np.diff(actual) / actual[:-1])\n",
    "stock_stats.append({\n",
    "    'symbol': symbol,\n",
    "    'cumulative_return': cumulative_return,\n",
    "    'volatility': volatility\n",
    "})\n",
    "\n",
    "rmse = math.sqrt(mean_squared_error(actual, pred))\n",
    "mae = mean_absolute_error(actual, pred)\n",
    "results[symbol] = {'RMSE': rmse, 'MAE': mae}\n",
    "\n",
    "# Plot Results\n",
    "plt.figure()\n",
    "plt.plot(actual, label='Actual')\n",
    "plt.plot(pred, label='Predicted')\n",
    "plt.title(f\"{symbol} - LSTM Forecast\")\n",
    "plt.xlabel(\"Test Day\")\n",
    "plt.ylabel(\"Price (USD)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58693d3e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Iterating over all the Symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4dc15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol in symbols:\n",
    "    print(f\"\\n=== Processing: {symbol} ===\")\n",
    "\n",
    "    # data, _ = ts.get_daily(symbol=symbol, outputsize='full')\n",
    "    # data = prepare_data(data)\n",
    "    data = load_or_fetch_data(symbol, api_key)\n",
    "    print(data.head())\n",
    "    data = add_technical_indicators(data)\n",
    "    X_selected, y_target = select_features(data)\n",
    "\n",
    "\n",
    "    print(\"X_selected\\n\",X_selected)\n",
    "    print(\"y_target\\n\",y_target)\n",
    "\n",
    "    merged_data = pd.concat([X_selected, y_target], axis=1).dropna().reset_index(drop=True)\n",
    "\n",
    "    actual, pred = lstm_forecast_multivariate(merged_data, target='close')\n",
    "\n",
    "    print(\"actual\\n\", actual)\n",
    "    print(\"pred\\n\", pred)\n",
    "\n",
    "    print(\"NaN count per column in merged_data:\")\n",
    "    print(merged_data.isna().sum())\n",
    "\n",
    "    # Storing the volatility and cumulative return\n",
    "    initial_price = actual[0]\n",
    "    final_price = actual[-1]\n",
    "    cumulative_return = (final_price - initial_price) / initial_price\n",
    "    volatility = np.std(np.diff(actual) / actual[:-1])\n",
    "    stock_stats.append({\n",
    "        'symbol': symbol,\n",
    "        'cumulative_return': cumulative_return,\n",
    "        'volatility': volatility\n",
    "    })\n",
    "\n",
    "    rmse = math.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    results[symbol] = {'RMSE': rmse, 'MAE': mae}\n",
    "\n",
    "    # Plot Results\n",
    "    plt.figure()\n",
    "    plt.plot(actual, label='Actual')\n",
    "    plt.plot(pred, label='Predicted')\n",
    "    plt.title(f\"{symbol} - LSTM Forecast\")\n",
    "    plt.xlabel(\"Test Day\")\n",
    "    plt.ylabel(\"Price (USD)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8120b6e",
   "metadata": {},
   "source": [
    "### Calssifying Stocks using ABC Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0b648de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_stocks_by_return(stock_stats_df):\n",
    "    # Sort by cumulative return descending\n",
    "    sorted_df = stock_stats_df.sort_values(by='cumulative_return', ascending=False).reset_index(drop=True)\n",
    "    n = len(sorted_df)\n",
    "    a_cutoff = int(0.2 * n)\n",
    "    b_cutoff = int(0.5 * n)\n",
    "\n",
    "    categories = ['A' if i < a_cutoff else 'B' if i < b_cutoff else 'C' for i in range(n)]\n",
    "    sorted_df['ABC'] = categories\n",
    "    return sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9778df9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stock Statistics DataFrame:\n",
      "  symbol  cumulative_return  volatility\n",
      "0   AAPL          -0.375998    0.028050\n",
      "1   MSFT           1.579285    0.017014\n",
      "2  GOOGL          -0.924096    0.035665\n",
      "3   TSLA          -0.565026    0.046570\n",
      "4   AMZN          -0.914634    0.034790\n",
      "\n",
      "Classified Stocks by Return:\n",
      "  symbol  cumulative_return  volatility ABC\n",
      "0   MSFT           1.579285    0.017014   A\n",
      "1   AAPL          -0.375998    0.028050   B\n",
      "2   TSLA          -0.565026    0.046570   C\n",
      "3   AMZN          -0.914634    0.034790   C\n",
      "4  GOOGL          -0.924096    0.035665   C\n",
      "\n",
      "ABC Classification Map:\n",
      "{'MSFT': 'A', 'AAPL': 'B', 'TSLA': 'C', 'AMZN': 'C', 'GOOGL': 'C'}\n"
     ]
    }
   ],
   "source": [
    "stock_stats_df = pd.DataFrame(stock_stats)\n",
    "print(\"\\nStock Statistics DataFrame:\")\n",
    "print(stock_stats_df)\n",
    "classified_df = classify_stocks_by_return(stock_stats_df)\n",
    "print(\"\\nClassified Stocks by Return:\")\n",
    "print(classified_df)\n",
    "abc_map = dict(zip(classified_df['symbol'], classified_df['ABC']))\n",
    "print(\"\\nABC Classification Map:\")\n",
    "print(abc_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca569efe",
   "metadata": {},
   "source": [
    "### Printing the Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d27f3dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Forecasting Performance Summary ====\n",
      "EURUSD: RMSE = 0.0102, MAE = 0.0076\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n==== Forecasting Performance Summary ====\")\n",
    "for sym, res in results.items():\n",
    "    print(f\"{sym}: RMSE = {res['RMSE']:.4f}, MAE = {res['MAE']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7468dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
